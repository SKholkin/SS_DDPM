{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "04172b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import torch\n",
    "from torch.distributions.beta import Beta\n",
    "from scipy import interpolate\n",
    "\n",
    "from beta import sufficient_stats_part2\n",
    "batch_size = 1024\n",
    "T = 1000\n",
    "import numpy as np\n",
    "device = 'cuda'\n",
    "\n",
    "from beta import get_dist\n",
    "\n",
    "def sample_t_batch(batch_size):\n",
    "    \n",
    "    cat_dist = torch.distributions.categorical.Categorical(1 / T * torch.ones([T]))\n",
    "    \n",
    "    t_batch = cat_dist.sample([batch_size]).to(device) + 1\n",
    "    \n",
    "    return t_batch\n",
    "\n",
    "def log_beta_fn(z_1, z_2):\n",
    "    return torch.special.gammaln(z_1) + torch.special.gammaln(z_2) - torch.special.gammaln(z_1 + z_2)\n",
    "\n",
    "def alpha_beta(mu, x_0):\n",
    "    return 1 + mu.reshape([-1, 1, 1, 1]) * x_0, 1 + mu.reshape([-1, 1, 1, 1]) * (1 - x_0)\n",
    "\n",
    "def KL(x_0, x_theta, t):\n",
    "    mu = noising_sch(t).reshape([-1, 1, 1, 1]) \n",
    "    alpha_0, beta_0 = alpha_beta(mu, x_0)\n",
    "    alpha_theta, beta_theta = alpha_beta(mu, x_theta)\n",
    "    kl_div = log_beta_fn(alpha_theta, beta_theta)\n",
    "    kl_div = kl_div - log_beta_fn(alpha_0, beta_0)\n",
    "    kl_div = kl_div + mu * (x_0 - x_theta) * ((torch.special.digamma(alpha_0) - torch.special.digamma(beta_0)))\n",
    "    return kl_div\n",
    "\n",
    "def sufficient_stats(x_t, t):\n",
    "    theta = noising_sch(t).reshape([-1, 1, 1, 1])\n",
    "    \n",
    "    return theta * torch.log(x_t / (1 - x_t))\n",
    "                                                 \n",
    "\n",
    "def noising_sch(t, mode='exp_cubic', theta_start=1e3, theta_end = 1e-3):\n",
    "    if mode == 'linear':\n",
    "        theta = theta_end + (T - t) / T * (theta_start - theta_end)\n",
    "    elif mode=='exp_linear': \n",
    "        log10_theta = np.log10(theta_end) + (T - t) / T * (np.log10(theta_start) - np.log10(theta_end))\n",
    "        theta = torch.pow(10, log10_theta)\n",
    "    elif mode=='exp_cubic':\n",
    "        spline = interpolate.CubicSpline([1, T * 0.3, T * 0.7, T], [3, 0.7, 0, -3])\n",
    "        log10_theta = torch.Tensor(spline(t.cpu().numpy()))\n",
    "        theta = torch.pow(10, log10_theta)\n",
    "    else:\n",
    "        raise BaseException('Unknown schedule mode')\n",
    "        \n",
    "    return torch.Tensor(theta).to(device)\n",
    "\n",
    "def sample_chain(t_batch, x_0):\n",
    "    samples = []\n",
    "    suff_stats = torch.zeros_like(x_0)\n",
    "    t_min = torch.min(t_batch)\n",
    "    helper = torch.Tensor([[t <= s for s in range(T + 1)] for t in t_batch]).to(device)\n",
    "    \n",
    "    for s in range(T, int(t_min), -1):\n",
    "        s_batch = torch.tensor([s], device=device).repeat(batch_size)\n",
    "        helper_slice = helper[:, s]\n",
    "        \n",
    "        theta = noising_sch(t_batch)\n",
    "        \n",
    "        alpha, beta = alpha_beta(theta, x_0)\n",
    "        \n",
    "        dist = Beta(alpha, beta)\n",
    "        samples.append(dist.sample())\n",
    "\n",
    "        suff_stats += helper_slice.reshape([-1, 1, 1, 1]) * sufficient_stats(samples[-1], s_batch)\n",
    "    return samples, suff_stats\n",
    "\n",
    "def generate_dataset_stats_normed(pic_dataloader, n_samples, batch_size=1024, save_path='generated_dataset.pth'):\n",
    "    n_iters = n_samples // batch_size\n",
    "    \n",
    "    x_0_storage = []\n",
    "    t_batch_storage = []\n",
    "    suff_stats_storage = []\n",
    "    \n",
    "    for i in tqdm(range(n_iters)):\n",
    "        x_0 = next(iter(pic_dataloader))[0].to(device)\n",
    "        t_batch = sample_t_batch(batch_size)\n",
    "        samples, suff_stats = sample_chain(t_batch, x_0)\n",
    "        \n",
    "        x_0_storage.append(x_0.cpu())\n",
    "        t_batch_storage.append(t_batch.cpu())\n",
    "        suff_stats_storage.append(suff_stats.cpu())\n",
    "        \n",
    "    x_0_tensor = torch.cat(x_0_storage, dim=0)\n",
    "    t_batch_tensor = torch.cat(t_batch_storage, dim=0)\n",
    "    suff_stats_tensor = torch.cat(suff_stats_storage, dim=0)\n",
    "    zero_tensor = torch.zeros_like(suff_stats_tensor)\n",
    "    \n",
    "    g_mean = [torch.mean(torch.where(t_batch_tensor.reshape([-1, 1, 1, 1]) == t, suff_stats_tensor, zero_tensor)) for t in range(T + 1)]\n",
    "    g_std = [torch.std(torch.where(t_batch_tensor.reshape([-1, 1, 1, 1]) == t, suff_stats_tensor, zero_tensor)) for t in range(T + 1)]\n",
    "    \n",
    "    pics = torch.cat([next(iter(pic_dataloader))[0] for i in range(n_iters)], dim=0)\n",
    "    \n",
    "    theta = noising_sch(torch.tensor([1], device='cpu').repeat(pics.shape[0]))\n",
    "    \n",
    "    theta = theta.cpu()\n",
    "    dist = get_dist(theta, pics)\n",
    "    \n",
    "    pics = dist.sample()\n",
    "    \n",
    "    suff_stats_part2_mean = torch.mean(sufficient_stats_part2(pics))\n",
    "    suff_stats_part2_std = torch.std(sufficient_stats_part2(pics))\n",
    "    \n",
    "    \n",
    "    torch.save(x_0_tensor, 'x_0_dataset.pth')\n",
    "    torch.save(t_batch_tensor, 't_batch_dataset.pth')\n",
    "    torch.save(suff_stats_tensor, 'suff_stats_dataset.pth')\n",
    "    \n",
    "    torch.save({'g_mean': g_mean, 'g_std': g_std, 'suff_stats_part2_mean': suff_stats_part2_mean,\n",
    "                'suff_stats_part2_std': suff_stats_part2_std},\n",
    "               'dataset_beta_stats.pth')\n",
    "    \n",
    "    return x_0_tensor, t_batch_tensor, suff_stats_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0538d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a5878ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 20/20 [05:58<00:00, 17.90s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from torchvision.datasets import MNIST\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "dataset = MNIST(root='MNIST', download=True,transform=transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "n_samples = 1024 * 20\n",
    "x_0_tensor, t_batch_tensor, suff_stats_tensor = generate_dataset_stats_normed(dataloader, n_samples, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d164b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412e828d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
